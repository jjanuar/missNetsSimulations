---
title: "20240619_coArrestLineGraph"
author: "Jon Januar"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

20241209 Update: the co-arrest part of this script is deprecated. The triangle-dense random graphs are still useful and is the primary aspect of this markdown.

## Preamble

```{r many fns}
## pakcages
library(here)
library(sna)
library(stringr)
library(igraph)

## BayesALAAM
source(here("Scripts", "bayesNetworkRoutines", "MultivarALAAMalt.R"))

# loading in london gangs because covariates...
# load in the london gangs dataset (Net 6)
load(here("Data", "20231006_missNetsEnMasse.RData"))

# take the specific adjmat
exampleMat = adjMatList[[6]]

# line graph functions
lineGraph <- function(adjMat, directed = FALSE){
  
  ## lineGraph(adjMat, directed) takes an adjacency matrix and generates its 
  ## corresponding line graph for its edges. 
  ##
  ## Input:
  ## - adjMat:   An adjacency matrix describing a graph. Not sure if missing data 
  ##             will mess with the conversion. 
  ##
  ## - directed: A logical value to indicate whether the graph is directed or not.
  ##
  ## Output:
  ## - The line graph for the input adjacency matrix, stored as another matrix.
  
  ### count the number of edges
  edgeCount = sum(adjMat)
  
  # if undirected, divide in half.
  if (directed == FALSE){
    edgeCount = edgeCount/2
    adjMat[lower.tri(adjMat)] = 0
  }
  
  # make a matrix of indices for edges (basically an edgelist)
  inds = which(adjMat == 1, arr.ind = TRUE)
  
  # order it for readability
  inds = inds[order(inds[,1]),]
  
  # make an empty matrix for the edges (represented as nodes)
  lineMat = matrix(data = 0, 
                   nrow = edgeCount,
                   ncol = edgeCount)
  
  # use the edge list to make the line graph matrix
  for(edgeInd in 1:edgeCount){                              # for every edge in the edge list
    tempMat = matrix(data = c(inds %in% inds[edgeInd,]),    # match the edge with the same nodes
                     ncol = 2)    
    tempMat[edgeInd,] = FALSE                               # remove the selected edge in the matches
    lineMat[edgeInd,] = tempMat[,1] + tempMat[,2]           # and put all the edges with the same nodes in the matrix
  }
  
  
  # make a vector of labels for the nodes
  nodeLabel = apply(inds,
                    MARGIN = 1,
                    FUN = toString)
  
  # remove whitespace
  nodeLabel = gsub(" ", "", nodeLabel, fixed = TRUE)
  
  # name the matrix
  rownames(lineMat) = nodeLabel
  
  # return the line graph matrix
  return(lineMat)
}

## calculating various metrics
getMetrics = function(net, directed = FALSE){
  
  # fork for directed/undirecited
  mode = "digraph"
  
  if(directed == FALSE){
    mode = "graph"
  } 
  
  # density
  density = gden(net, mode = mode)
  
  # clustering coefficient
  clustCoeff = gtrans(net, mode = mode)
  
  # centralisation
  centralisation = centralization(net, FUN = sna::degree, mode = mode)
  
  # average geodesic
  avgGeod = mean(geodist(net, inf.replace= NA)$gdist, na.rm = T)
  
  # diameter
  diameter = max(geodist(net, inf.replace= NA)$gdist, na.rm = T)
  
  # avg degree
  avgDegree = mean(sna::degree(net, gmode = mode))
  
  # avg betweenness
  avgBetw = mean(sna::betweenness(net, gmode = mode))
  
  # number of isolates
  numIsolates = length(isolates(net))
  
  # slap them all in a list
  metricList = list(
    density = density,
    clustCoeff = clustCoeff,
    centralisation = centralisation,
    avgGeod = avgGeod,
    diameter = diameter,
    avgDegree = avgDegree,
    avgBetw = avgBetw,
    numIsolates = numIsolates
  )
  
  # reutrn the metric list
  return(metricList)
}

# tie no tie function
swapTie = function(graph){
  
    
  # grab the edge list
  edgeList = which(graph == 1, arr.ind = TRUE)
  
  # and the null tie list
  nullTieList = which(graph == 0, arr.ind = TRUE)
  
  # exclude the diagonals
  nullTieDiag = (nullTieList[,1] == nullTieList[,2])
  
  # and subset
  nullTieList = nullTieList[!nullTieDiag,]
  
  
  # choose a triom edge
  edgeIndex = sample(1:nrow(edgeList), size = 1)
  chosenEdge = edgeList[edgeIndex, ]
  
  # get the other edge (becuase undireced) and index
  otherChosenEdge = edgeList[((edgeList[,1] == chosenEdge[2]) & (edgeList[,2] == chosenEdge[1])), ]
  otherEdgeIndex = c(1:nrow(edgeList))[(edgeList[,1] == chosenEdge[2]) & (edgeList[,2] == chosenEdge[1])]
  
  # and now the same for the null ties
  nullTieIndex = sample(1:nrow(nullTieList), size = 1)
  chosenNullTie = nullTieList[nullTieIndex, ]
  otherNullTie = nullTieList[((nullTieList[,1] == chosenNullTie[2]) & (nullTieList[,2] == chosenNullTie[1])), ]
  otherNullTieIndex = c(1:nrow(nullTieList))[(nullTieList[,1] == chosenNullTie[2]) & (nullTieList[,2] == chosenNullTie[1])]
  
  # swap these two (... four.)
  edgeList[edgeIndex, ] = nullTieList[nullTieIndex, ]
  edgeList[otherEdgeIndex, ] = nullTieList[otherNullTieIndex, ]
  nullTieList[nullTieIndex, ] = chosenEdge
  nullTieList[otherNullTieIndex, ] = otherChosenEdge
  
  # and the resulting edge list would contain the same no. of edges but one of the null ties is a tie and vice versa
  # reconstruct the graph
  swappedGraph = matrix(data = 0, nrow = nrow(randGraph), ncol = ncol(randGraph))
  
  # ... loop.
  for(edgeInd in 1:nrow(edgeList)){
    
    # turn into an edge
    swappedGraph[edgeList[edgeInd,1], edgeList[edgeInd, 2]] = 1
    
  }
  
  # a check to make sure the edge lists are equal
  checkEdgeList = which(swappedGraph==1, arr.ind = TRUE)
  
  # we want 0
  if(sum(edgeList[order(edgeList), ] != checkEdgeList[order(checkEdgeList), ]) > 0){
    
    stop("Reconstructed graph has more edges than input graph")
    
  }
  
  # return the reconstrctued swapped graph
  return(swappedGraph)
  

}

## triangle functions

# no. of triangles
triCount = function(x){
  as.numeric(sna::triad.census(x)[,"300"])
}

# the objective function is
triDiff = function(x, triTarget){
  (triCount(x) - triTarget)^2
}

# target distribution woul dbe
target = function(theta, triDiff){
  
  x = theta * triDiff
  
  return(ifelse(x<0,0,-x))
}

# the MCMC function
triGraphMcmc = function(initGraph, tuningCons, triTarget, iterations){
  
  ## triGraphMcmc(graphArray, thetas, ...) is an MCMC that uses simulated annealing that samples a distribution
  ## of fixed-density graphs that have been indexed by a parameter to achieve the target number of triangles.
  ##
  ## Input:
  ## - initGraph: An n x n graph that initialises the sampler. Currently can only accommodate undirected graphs.
  ##
  ## - tuningCons: A float to increase (or decrease) the theta value after each iteration.
  ##
  ## - triTarget:  An integer for the target number of triangles.
  ##
  ## - iterations: An integer for the number of iterations for the sampler to run. Also the number of graphs
  ##
  ## Output: 
  ## - graphArray: An n x n x #iterations array that contains #iterations graphs.
  ##
  ## - triDiffVec: A #iterations-long vector containing the squared difference between proposed and target
  ##               triangle counts.
  ##
  ## - thetas:     A #iterations-long vector containing the parameter value that increases over time (annealing).
  ##               This sole parameter weighs the squared difference between proposed and target triangle counts.
  
  
  # initialising data structures
  # the graph array
  n = nrow(initGraph)
  graphArray = array(data = NA, dim = c(n, n, iterations))
  graphArray[,,1] = initGraph
  
  # the triangle difference vector
  triDiffVec = rep(0, times = iterations)
  initTriDiff = triDiff(x = initGraph, triTarget = triTarget)
  triDiffVec[1] = initTriDiff
  
  # the parameter values
  thetas = rep(0, times = iterations)
  thetas[1] = 1
  
  # A quick branch to check if the initial graph has too few triangles
  if(initTriDiff > 1000){
  
    stop("Triangle difference too large")
  }
  
  # loop
  for(i in 2:iterations){
    
    # set current graph
    currentGraph = graphArray[,,i-1]
    thetas[i] = thetas[i-1] * tuningCons
    currentTheta = thetas[i]
    
    # propose random graph
    proposedGraph = swapTie(graph = currentGraph)
    
    # count triangles
    proposedTriDiff = triDiff(x = proposedGraph, triTarget = triTarget)
    currentTriDiff = triDiff(x = currentGraph, triTarget = triTarget)
    
    # save the tridiff
    triDiffVec[i] = proposedTriDiff
  
    # then plug it into the target distribution
    acceptRatio = target(theta = currentTheta, triDiff = proposedTriDiff) - target(theta = currentTheta, triDiff = currentTriDiff) 
  
    # accept the proposed changes or stay at current graph
    if(log(runif(1)) < acceptRatio){
      
      # move
      graphArray[,, i] = proposedGraph
    } else{
      
      # stay
      graphArray[,, i] = currentGraph
    }
  }
  
  # output stuff
  # list because R
  outList = list('graphArray' = graphArray,
                 'triDiffVec' = triDiffVec,
                 'thetas' = thetas)
  return(outList)
  
}

```

## Simulate triangle-dense graphs

```{r tristuff}
# and now we run, initialise 54 nodes
# and roghly a density of 10%
randGraph = rgnm(n = 1,
                 nv = 54,
                 m  = floor(0.10 * ((54*53)/2)) ,
                 mode = "graph")

while(triCount(randGraph) < 40){
  randGraph = rgnm(n = 1,
                 nv = 54,
                 m  = floor(0.1 * ((54*53)/2)) ,
                 mode = "graph")
}


# run a couple times to get a clust coeff
triGraph = triGraphMcmc(initGraph = randGraph,
                        tuningCons = 1.01,
                        triTarget = 60,
                        iterations = 1000)

prevGraph = triGraph$graphArray[,,1000]

triGraph = triGraphMcmc(initGraph = prevGraph,
                        tuningCons = 1.01,
                        triTarget = 85,
                        iterations = 1000)

prevGraph = triGraph$graphArray[,,1000]

triGraph = triGraphMcmc(initGraph = prevGraph,
                        tuningCons = 1.01,
                        triTarget = 110,
                        iterations = 1000)

prevGraph = triGraph$graphArray[,,1000]

triGraph = triGraphMcmc(initGraph = prevGraph,
                        tuningCons = 1.01,
                        triTarget = 135,
                        iterations = 1000)

# prevGraph = triGraph$graphArray[,,1000]
# 
# triGraph = triGraphMcmc(initGraph = prevGraph,
#                         tuningCons = 1.01,
#                         triTarget = 160,
#                         iterations = 1000)
# 
# prevGraph = triGraph$graphArray[,,1000]
# 
# triGraph = triGraphMcmc(initGraph = prevGraph,
#                         tuningCons = 1.01,
#                         triTarget = 180,
#                         iterations = 1000)
# 
# 
# prevGraph = triGraph$graphArray[,,1000]
# 
# triGraph = triGraphMcmc(initGraph = prevGraph,
#                         tuningCons = 1.01,
#                         triTarget = 200,
#                         iterations = 1000)
# 
# prevGraph = triGraph$graphArray[,,1000]
# 
# triGraph = triGraphMcmc(initGraph = prevGraph,
#                         tuningCons = 1.01,
#                         triTarget = 220,
#                         iterations = 1000)
# prevGraph = triGraph$graphArray[,,1000]
# 
# triGraph = triGraphMcmc(initGraph = prevGraph,
#                         tuningCons = 1.01,
#                         triTarget = 240,
#                         iterations = 1000)
# 
# prevGraph = triGraph$graphArray[,,1000]
# 
# triGraph = triGraphMcmc(initGraph = prevGraph,
#                         tuningCons = 1.01,
#                         triTarget = 260,
#                         iterations = 1000)
# 
# prevGraph = triGraph$graphArray[,,1000]
# 
# triGraph = triGraphMcmc(initGraph = prevGraph,
#                         tuningCons = 1.01,
#                         triTarget = 280,
#                        iterations = 1000)

# a count of 100 seems sufficient...
clustCoeffTriGraph = apply(triGraph$graphArray, MARGIN = 3, FUN = gtrans, mode = "graph")
plot(ts(clustCoeffTriGraph))

# just sample the graph with the highest clust coeff
chosenTriGraph = triGraph$graphArray[,, sample(801:1000, size  =1)]

# plot it
gplot(chosenTriGraph, gmode = "graph")

```


## Simulate coarrest network

```{r coarrest, echo = F, eval = F}
# set some parameters of the bip net
actorNo = 54
eventNo = 15
fixDens = 0.10

bipEdgeNo = floor(fixDens * (actorNo * eventNo))

# try it out
sampledBip = sample_bipartite(n1 = actorNo,
                              n2 = eventNo,
                              type = "gnm",
                              m = bipEdgeNo)

# can check the bip matrix
bipMat = as_biadjacency_matrix(sampledBip)

# and get the one-mode projections
coEvent = bipartite_projection(sampledBip)$proj1

# turn into a matrix, needs to be done twice because igraph
coEventMat = as.matrix(as_adj(coEvent))

# plot it
gplot(coEventMat, gmode = "graph")
gplot(bipMat, gmode = "twomode", usearrows = FALSE)

```


## More line graph sims

The pipeline for this is:


1. Turn the graphs into line graphs
    + Turn any node covariates into edge covariates in the meantime 
    + For the purely simulated graphs, we can just use the degree as a covariate

2. Initialise the outcome variable (sampling indicator)

3. Specify a sampling rate (I've been using 0.65 for about a third missing)

4. Run the BayesALAAM (with contagion) for initialising theta means

5. Iterate the contagion values and check that they're changing

6. Get the simulated networks

7. And get the metrics

8. Plot the metrics.
  


### Triangle dense graphs

#### Simulations

```{r line graph sim trigraph}
# trigraph

# line graph of the triangledense network
triLineGraph = lineGraph(chosenTriGraph)

## Slapping on a covariate
# get unique ids for dyadic cov
triLineStr = str_split(rownames(triLineGraph), pattern = ",")

# reformat into a more friendly data frame
triLineEdgeList = data.frame(sender = as.numeric(unlist(lapply(triLineStr, FUN = function(x){x[1]}))), 
                              receiver = as.numeric(unlist(lapply(triLineStr, FUN = function(x){x[2]}))))

# get the degree
triDegVec = rowSums(chosenTriGraph)

# turn into a 'edge' covariate using the indices in the edge list data frame
triDegreeCov = c()
centeredAge = (londonGangsAtt$Age - mean(londonGangsAtt$Age))/sd(londonGangsAtt$Age)

# turn into a 'edge' covariate using the indices in the edge list data frame
centAgeDiffEdgeCov = c()

# just loop it
for(edgeNo in 1:nrow(triLineEdgeList)){

  sender = triLineEdgeList[edgeNo, "sender"]
  receiver = triLineEdgeList[edgeNo, "receiver"]

  centAgeDiffEdgeCov[edgeNo] = centeredAge[sender] - centeredAge[receiver]
  triDegreeCov[edgeNo] = triDegVec[sender] + triDegVec[receiver]
}

# rescaling the degree covariate since its high values are giving me parameter scale grief
centTriDegCov = triDegreeCov/max(triDegreeCov)

# line covs
#triAlaamCovs = cbind(centTriDegCov)
triAlaamCovs = cbind(centAgeDiffEdgeCov)

# make an empty outcome variable
triLineOutcome = rep(0, times = nrow(triLineGraph))

# specifying a sampling rate to fix, say 50% sampled (50% missing)
fixSampledRate = 0.50

# I want the density to be very precise so I'll try using less probabilistic sampling (less randomness)
# so turn that density to a number of sampled edges, rounding down
fixSampledEdges = floor(fixSampledRate *nrow(triLineGraph))

# use the number of fixed sampled edges as the sum of some kind of index for which variable in lineOutcome is sampled
triSampledIndex = sample(1:nrow(triLineGraph), fixSampledEdges, replace = FALSE)

# and turn them into sampled edges
triLineOutcome[triSampledIndex] = 1

# check to see if it's equal
sum(triLineOutcome) == fixSampledEdges

## Needs some kind of covariate... we can use the same as the one for the empirical covert network.
triContAlaam <- BayesALAAM(y = triLineOutcome,           # dependent variable
                            ADJ = triLineGraph,           # 'network'
                            covariates = triAlaamCovs,
                            directed = FALSE,    # directed / undirecred network
                            useDegree = FALSE,
                            burnin = 1000,
                            Iterations = 5000,   # number of iterations
                            saveFreq = 500)

# plot it to check the chains
plot(ts(triContAlaam$Theta))

# grab the means
triContThetaMeans <- colMeans(triContAlaam$Theta)

# then a null contagion model
triNullAlaam <- BayesALAAM(y = triLineOutcome,           # dependent variable
                            ADJ = triLineGraph,           # 'network'
                            covariates = triAlaamCovs,   # covariates
                            directed = FALSE,    # directed / undirecred network
                            useDegree = FALSE,
                            burnin = 1000,
                            Iterations = 5000,   # number of iterations
                            saveFreq = 500,
                            contagion = 'none') 

# plot it to check the chains
plot(ts(triNullAlaam$Theta))

# grab the means
triNullThetaMeans <- colMeans(triNullAlaam$Theta)

# simulating the outcome of the alaam object using the null thetas.
triNullAlaamSim <- simulate.alaam(ALAAMobj=triContAlaam$ALAAMobj,
                            theta=triNullThetaMeans,
                            contagion ='simple', 
                            thinning = 30, 
                            NumIterations = 10000, 
                            burnin = 5000, 
                            DoSave=TRUE, 
                            returnNet= TRUE, 
                            doGOF=FALSE)

# inspecting the object
class(triNullAlaamSim$statsvec)
dim(triNullAlaamSim$statsvec)
dim(cov(t(triNullAlaamSim$statsvec)))

## I'm breaking apart Johan's increment_theta function
# let's say we want to increase the number of contagion occurrences by 5
contIncrement = -1

# set up some number of iterations for the simulations
iterations = 20

# let's plug that into a vector for increments
incrementVector = matrix(0, nrow = length(triNullThetaMeans), ncol =  1)

# and plug that into the contagion parameter
incrementVector[2,1] = contIncrement

# some data structures for the simulations
meanStats = matrix(0, nrow = iterations, ncol = length(triNullThetaMeans))
lowerStats =  matrix(0, nrow = iterations, ncol = length(triNullThetaMeans))
upperStats =  matrix(0, nrow = iterations, ncol = length(triNullThetaMeans))
updatedTheta = matrix(0, nrow = iterations, ncol = length(triNullThetaMeans))
currentTheta = triNullThetaMeans

# the main simulation loop
for(iterIndex in 1:iterations){
  
  # simulate contagion
  iterAlaamSim = simulate.alaam(ALAAMobj = triContAlaam$ALAAMobj,
                            theta=t(currentTheta),
                            contagion ='simple', 
                            thinning = 30, 
                            NumIterations = 10000, 
                            burnin = 5000, 
                            DoSave=TRUE, 
                            returnNet= TRUE, 
                            doGOF=FALSE)
  
  # update the current theta
  currentTheta = currentTheta - solve(cov(t(iterAlaamSim$statsvec))) %*% incrementVector
  
  # save all of those simulated statistics
  meanStats[iterIndex, ] = rowMeans(iterAlaamSim$statsvec)
  
  # and for each parameter...
  for(paraIndex in 1:length(triNullThetaMeans)){
    
    # order the simulated statistics and grab the 95% CI
    orderedStats = sort(iterAlaamSim$statsvec[paraIndex, ])
    lowerStats[iterIndex, paraIndex] = quantile(orderedStats, probs = 0.025)
    upperStats[iterIndex, paraIndex] = quantile(orderedStats, probs = 0.975)
  }
  
  # save the updated theta
  updatedTheta[iterIndex, ] = t(currentTheta)
}

# all of the object should be filled at the end of this main loop
# so we can shove all of it in a list
contIncrementResult = list(meanStats = meanStats,
                           updatedTheta = updatedTheta,
                           lowerStats = lowerStats,
                           upperStats = upperStats)


# plots to check if it works
par(mfrow=c(3,2))
for (paraIndex in 1:length(triNullThetaMeans)){
  
  # plotting the mean simulated statistics
  plot(ts(contIncrementResult$meanStats[, paraIndex]), 
       ylim = range(contIncrementResult$meanStats[, paraIndex],
                  contIncrementResult$lowerStats[, paraIndex],
                  contIncrementResult$upperStats[, paraIndex]),
     main = names(triNullThetaMeans)[paraIndex],
     ylab = NA,
     xlab = NA)
  
  # adding the lower and upper bounds
  lines(x = c(1:nrow(contIncrementResult$meanStats)), 
        y = contIncrementResult$lowerStats[, paraIndex],col='red')
  lines(x = c(1:nrow(contIncrementResult$meanStats)), 
        y = contIncrementResult$upperStats[, paraIndex],col='red')
}

#  no contagion, taking nullAlaamSim
zeroSimStats = t(triNullAlaamSim$statsvec)

# sampled edges
zeroSampledEdges = t(triNullAlaamSim$y)

## Briefly inspect it
summary(zeroSimStats)

# Now let's increment it by an arbitrarily 'small' amount to emulate a 'small' amount of contagion
# let's say we want to increase the number of contagion occurrences by 5
contIncrement = -30

# set up some number of iterations for the simulations, 2 for this case, one to initialise and another one for the single contagion increment
iterations = 2

# let's plug that into a vector for increments
incrementVector = matrix(0, nrow = length(triNullThetaMeans), ncol =  1)

# and plug that into the contagion parameter
incrementVector[2,1] = contIncrement

# some data structures for the simulations
meanStats = matrix(0, nrow = iterations, ncol = length(triNullThetaMeans))
lowerStats =  matrix(0, nrow = iterations, ncol = length(triNullThetaMeans))
upperStats =  matrix(0, nrow = iterations, ncol = length(triNullThetaMeans))
updatedTheta = matrix(0, nrow = iterations, ncol = length(triNullThetaMeans))
currentTheta = triNullThetaMeans

# the main simulation loop
for(iterIndex in 1:iterations){
  
  # simulate contagion
  smallContSim = simulate.alaam(ALAAMobj = triContAlaam$ALAAMobj,
                            theta=t(currentTheta),
                            contagion ='simple', 
                            thinning = 30, 
                            NumIterations = 10000, 
                            burnin = 5000, 
                            DoSave=TRUE, 
                            returnNet= TRUE, 
                            doGOF=FALSE)
  
  # update the current theta
  currentTheta = currentTheta - solve(cov(t(smallContSim$statsvec))) %*% incrementVector
  
  # save all of those simulated statistics
  meanStats[iterIndex, ] = rowMeans(smallContSim$statsvec)
  
  # and for each parameter...
  for(paraIndex in 1:length(triNullThetaMeans)){
    
    # order the simulated statistics and grab the 95% CI
    orderedStats = sort(smallContSim$statsvec[paraIndex, ])
    lowerStats[iterIndex, paraIndex] = quantile(orderedStats, probs = 0.025)
    upperStats[iterIndex, paraIndex] = quantile(orderedStats, probs = 0.975)
  }
  
  # save the updated theta
  updatedTheta[iterIndex, ] = t(currentTheta)
}

# all of the object should be filled at the end of this main loop
# so we can shove all of it in a list
contIncrementResult = list(meanStats = meanStats,
                           updatedTheta = updatedTheta,
                           lowerStats = lowerStats,
                           upperStats = upperStats)

par(mfrow=c(3,2))
for (paraIndex in 1:length(triNullThetaMeans)){
  
  # plotting the mean simulated statistics
  plot(ts(contIncrementResult$meanStats[, paraIndex]), 
       ylim = range(contIncrementResult$meanStats[, paraIndex],
                  contIncrementResult$lowerStats[, paraIndex],
                  contIncrementResult$upperStats[, paraIndex]),
     main = names(triNullThetaMeans)[paraIndex],
     ylab = NA,
     xlab = NA)
  
  # adding the lower and upper bounds
  lines(x = c(1:nrow(contIncrementResult$meanStats)), 
        y = contIncrementResult$lowerStats[, paraIndex],col='red')
  lines(x = c(1:nrow(contIncrementResult$meanStats)), 
        y = contIncrementResult$upperStats[, paraIndex],col='red')
}

# taking the small contagion information out
#  no contagion, taking nullAlaamSim
smallSimStats = t(smallContSim$statsvec)

# sampled edges
smallSampledEdges = t(smallContSim$y)

## Briefly inspect it
summary(smallSimStats)

## Same thing, but large
# Now let's increment it by an arbitrarily 'small' amount to emulate a 'small' amount of contagion
# let's say we want to increase the number of contagion occurrences by 5
contIncrement = -50

# set up some number of iterations for the simulations, 2 for this case, one to initialise and another one for the single contagion increment
iterations = 2

# let's plug that into a vector for increments
incrementVector = matrix(0, nrow = length(triNullThetaMeans), ncol =  1)

# and plug that into the contagion parameter
incrementVector[2,1] = contIncrement

# some data structures for the simulations
meanStats = matrix(0, nrow = iterations, ncol = length(triNullThetaMeans))
lowerStats =  matrix(0, nrow = iterations, ncol = length(triNullThetaMeans))
upperStats =  matrix(0, nrow = iterations, ncol = length(triNullThetaMeans))
updatedTheta = matrix(0, nrow = iterations, ncol = length(triNullThetaMeans))
currentTheta = currentTheta

# the main simulation loop
for(iterIndex in 1:iterations){
  
  # simulate contagion
  largeContSim = simulate.alaam(ALAAMobj = triContAlaam$ALAAMobj,
                            theta=t(currentTheta),
                            contagion ='simple', 
                            thinning = 30, 
                            NumIterations = 10000, 
                            burnin = 5000, 
                            DoSave=TRUE, 
                            returnNet= TRUE, 
                            doGOF=FALSE)
  
  # update the current theta
  currentTheta = currentTheta - solve(cov(t(largeContSim$statsvec))) %*% incrementVector
  
  # save all of those simulated statistics
  meanStats[iterIndex, ] = rowMeans(largeContSim$statsvec)
  
  # and for each parameter...
  for(paraIndex in 1:length(triNullThetaMeans)){
    
    # order the simulated statistics and grab the 95% CI
    orderedStats = sort(largeContSim$statsvec[paraIndex, ])
    lowerStats[iterIndex, paraIndex] = quantile(orderedStats, probs = 0.025)
    upperStats[iterIndex, paraIndex] = quantile(orderedStats, probs = 0.975)
  }
  
  # save the updated theta
  updatedTheta[iterIndex, ] = t(currentTheta)
}

# all of the object should be filled at the end of this main loop
# so we can shove all of it in a list
contIncrementResult = list(meanStats = meanStats,
                           updatedTheta = updatedTheta,
                           lowerStats = lowerStats,
                           upperStats = upperStats)

par(mfrow=c(3,2))
for (paraIndex in 1:length(triNullThetaMeans)){
  
  # plotting the mean simulated statistics
  plot(ts(contIncrementResult$meanStats[, paraIndex]), 
       ylim = range(contIncrementResult$meanStats[, paraIndex],
                  contIncrementResult$lowerStats[, paraIndex],
                  contIncrementResult$upperStats[, paraIndex]),
     main = names(triNullThetaMeans)[paraIndex],
     ylab = NA,
     xlab = NA)
  
  # adding the lower and upper bounds
  lines(x = c(1:nrow(contIncrementResult$meanStats)), 
        y = contIncrementResult$lowerStats[, paraIndex],col='red')
  lines(x = c(1:nrow(contIncrementResult$meanStats)), 
        y = contIncrementResult$upperStats[, paraIndex],col='red')
}

# taking the large contagion information out
largeSimStats = t(largeContSim$statsvec)

# sampled edges
largeSampledEdges = t(largeContSim$y)

## Briefly inspect it
summary(largeSimStats)


```


```{r line graph sim trigraph test2, eval = F, echo = F}
# trigraph

triAlaamCovs2 = cbind(centTriDegCov)

## Needs some kind of covariate... we can use the same as the one for the empirical covert network.
triContAlaam2 <- BayesALAAM(y = triLineOutcome,           # dependent variable
                            ADJ = triLineGraph,           # 'network'
                            covariates = triAlaamCovs2,
                            directed = FALSE,    # directed / undirecred network
                            useDegree = FALSE,
                            burnin = 1000,
                            Iterations = 5000,   # number of iterations
                            saveFreq = 500)

# plot it to check the chains
plot(ts(triContAlaam2$Theta))

# grab the means
triContThetaMeans2 <- colMeans(triContAlaam2$Theta)

# then a null contagion model
triNullAlaam2 <- BayesALAAM(y = triLineOutcome,           # dependent variable
                            ADJ = triLineGraph,           # 'network'
                            covariates = triAlaamCovs2,   # covariates
                            directed = FALSE,    # directed / undirecred network
                            useDegree = FALSE,
                            burnin = 1000,
                            Iterations = 5000,   # number of iterations
                            saveFreq = 500,
                            contagion = 'none') 

# plot it to check the chains
plot(ts(triNullAlaam2$Theta))

# grab the means
triNullThetaMeans2 <- colMeans(triNullAlaam2$Theta)

# simulating the outcome of the alaam object using the null thetas.
triNullAlaamSim2 <- simulate.alaam(ALAAMobj=triContAlaam2$ALAAMobj,
                            theta=triNullThetaMeans2,
                            contagion ='simple', 
                            thinning = 30, 
                            NumIterations = 10000, 
                            burnin = 5000, 
                            DoSave=TRUE, 
                            returnNet= TRUE, 
                            doGOF=FALSE)

# inspecting the object
class(triNullAlaamSim2$statsvec)
dim(triNullAlaamSim2$statsvec)
dim(cov(t(triNullAlaamSim2$statsvec)))

## I'm breaking apart Johan's increment_theta function
# let's say we want to increase the number of contagion occurrences by 5
contIncrement2 = -1

# set up some number of iterations for the simulations
iterations2 = 20

# let's plug that into a vector for increments
incrementVector2 = matrix(0, nrow = length(triNullThetaMeans2), ncol =  1)

# and plug that into the contagion parameter
incrementVector2[2,1] = contIncrement2

# some data structures for the simulations
meanStats2 = matrix(0, nrow = iterations2, ncol = length(triNullThetaMeans2))
lowerStats2 =  matrix(0, nrow = iterations2, ncol = length(triNullThetaMeans2))
upperStats2 =  matrix(0, nrow = iterations2, ncol = length(triNullThetaMeans2))
updatedTheta2 = matrix(0, nrow = iterations2, ncol = length(triNullThetaMeans2))
currentTheta2 = triNullThetaMeans2

# the main simulation loop
for(iterIndex in 1:iterations2){
  
  # simulate contagion
  iterAlaamSim2 = simulate.alaam(ALAAMobj = triContAlaam2$ALAAMobj,
                            theta=t(currentTheta2),
                            contagion ='simple', 
                            thinning = 30, 
                            NumIterations = 10000, 
                            burnin = 5000, 
                            DoSave=TRUE, 
                            returnNet= TRUE, 
                            doGOF=FALSE)
  
  # update the current theta
  currentTheta2 = currentTheta2 - solve(cov(t(iterAlaamSim2$statsvec))) %*% incrementVector2
  
  # save all of those simulated statistics
  meanStats2[iterIndex, ] = rowMeans(iterAlaamSim2$statsvec)
  
  # and for each parameter...
  for(paraIndex in 1:length(triNullThetaMeans2)){
    
    # order the simulated statistics and grab the 95% CI
    orderedStats2 = sort(iterAlaamSim2$statsvec[paraIndex, ])
    lowerStats2[iterIndex, paraIndex] = quantile(orderedStats2, probs = 0.025)
    upperStats2[iterIndex, paraIndex] = quantile(orderedStats2, probs = 0.975)
  }
  
  # save the updated theta
  updatedTheta2[iterIndex, ] = t(currentTheta2)
}

# all of the object should be filled at the end of this main loop
# so we can shove all of it in a list
contIncrementResult2 = list(meanStats = meanStats2,
                           updatedTheta = updatedTheta2,
                           lowerStats = lowerStats2,
                           upperStats = upperStats2)


# plots to check if it works
par(mfrow=c(3,2))
for (paraIndex in 1:length(triNullThetaMeans2)){
  
  # plotting the mean simulated statistics
  plot(ts(contIncrementResult2$meanStats[, paraIndex]), 
       ylim = range(contIncrementResult2$meanStats[, paraIndex],
                  contIncrementResult2$lowerStats[, paraIndex],
                  contIncrementResult2$upperStats[, paraIndex]),
     main = names(triNullThetaMeans2)[paraIndex],
     ylab = NA,
     xlab = NA)
  
  # adding the lower and upper bounds
  lines(x = c(1:nrow(contIncrementResult2$meanStats)), 
        y = contIncrementResult2$lowerStats[, paraIndex],col='red')
  lines(x = c(1:nrow(contIncrementResult2$meanStats)), 
        y = contIncrementResult2$upperStats[, paraIndex],col='red')
}

#  no contagion, taking nullAlaamSim
zeroSimStats2 = t(triNullAlaamSim2$statsvec)

# sampled edges
zeroSampledEdges2 = t(triNullAlaamSim2$y)

## Briefly inspect it
summary(zeroSimStats2)

# Now let's increment it by an arbitrarily 'small' amount to emulate a 'small' amount of contagion
# let's say we want to increase the number of contagion occurrences by 5
contIncrement2 = -5

# set up some number of iterations for the simulations, 2 for this case, one to initialise and another one for the single contagion increment
iterations2 = 2

# let's plug that into a vector for increments
incrementVector2 = matrix(0, nrow = length(triNullThetaMeans2), ncol =  1)

# and plug that into the contagion parameter
incrementVector2[2,1] = contIncrement2

# some data structures for the simulations
meanStats2 = matrix(0, nrow = iterations2, ncol = length(triNullThetaMeans2))
lowerStats2 =  matrix(0, nrow = iterations2, ncol = length(triNullThetaMeans2))
upperStats2 =  matrix(0, nrow = iterations2, ncol = length(triNullThetaMeans2))
updatedTheta2 = matrix(0, nrow = iterations2, ncol = length(triNullThetaMeans2))
currentTheta2 = triNullThetaMeans2

# the main simulation loop
for(iterIndex in 1:iterations2){
  
  # simulate contagion
  smallContSim2 = simulate.alaam(ALAAMobj = triContAlaam2$ALAAMobj,
                            theta=t(currentTheta2),
                            contagion ='simple', 
                            thinning = 30, 
                            NumIterations = 10000, 
                            burnin = 5000, 
                            DoSave=TRUE, 
                            returnNet= TRUE, 
                            doGOF=FALSE)
  
  # update the current theta
  currentTheta2 = currentTheta2 - solve(cov(t(smallContSim2$statsvec))) %*% incrementVector2
  
  # save all of those simulated statistics
  meanStats2[iterIndex, ] = rowMeans(smallContSim2$statsvec)
  
  # and for each parameter...
  for(paraIndex in 1:length(triNullThetaMeans2)){
    
    # order the simulated statistics and grab the 95% CI
    orderedStats2 = sort(smallContSim2$statsvec[paraIndex, ])
    lowerStats2[iterIndex, paraIndex] = quantile(orderedStats2, probs = 0.025)
    upperStats2[iterIndex, paraIndex] = quantile(orderedStats2, probs = 0.975)
  }
  
  # save the updated theta
  updatedTheta2[iterIndex, ] = t(currentTheta2)
}

# all of the object should be filled at the end of this main loop
# so we can shove all of it in a list
contIncrementResult2 = list(meanStats = meanStats2,
                           updatedTheta = updatedTheta2,
                           lowerStats = lowerStats2,
                           upperStats = upperStats2)

par(mfrow=c(3,2))
for (paraIndex in 1:length(triNullThetaMeans2)){
  
  # plotting the mean simulated statistics
  plot(ts(contIncrementResult2$meanStats[, paraIndex]), 
       ylim = range(contIncrementResult2$meanStats[, paraIndex],
                  contIncrementResult2$lowerStats[, paraIndex],
                  contIncrementResult2$upperStats[, paraIndex]),
     main = names(triNullThetaMeans2)[paraIndex],
     ylab = NA,
     xlab = NA)
  
  # adding the lower and upper bounds
  lines(x = c(1:nrow(contIncrementResult2$meanStats)), 
        y = contIncrementResult2$lowerStats[, paraIndex],col='red')
  lines(x = c(1:nrow(contIncrementResult2$meanStats)), 
        y = contIncrementResult2$upperStats[, paraIndex],col='red')
}

# taking the small contagion information out
#  no contagion, taking nullAlaamSim
smallSimStats2 = t(smallContSim2$statsvec)

# sampled edges
smallSampledEdges2 = t(smallContSim2$y)

## Briefly inspect it
summary(smallSimStats2)

## Same thing, but large
# Now let's increment it by an arbitrarily 'small' amount to emulate a 'small' amount of contagion
# let's say we want to increase the number of contagion occurrences by 5
contIncrement2 = -100

# set up some number of iterations for the simulations, 2 for this case, one to initialise and another one for the single contagion increment
iterations2 = 2

# let's plug that into a vector for increments
incrementVector2 = matrix(0, nrow = length(triNullThetaMeans2), ncol =  1)

# and plug that into the contagion parameter
incrementVector2[2,1] = contIncrement2

# some data structures for the simulations
meanStats2 = matrix(0, nrow = iterations, ncol = length(triNullThetaMeans2))
lowerStats2 =  matrix(0, nrow = iterations, ncol = length(triNullThetaMeans2))
upperStats2 =  matrix(0, nrow = iterations, ncol = length(triNullThetaMeans2))
updatedTheta2 = matrix(0, nrow = iterations, ncol = length(triNullThetaMeans2))
currentTheta2 = triNullThetaMeans2

# the main simulation loop
for(iterIndex in 1:iterations2){
  
  # simulate contagion
  largeContSim2 = simulate.alaam(ALAAMobj = triContAlaam2$ALAAMobj,
                            theta=t(currentTheta2),
                            contagion ='simple', 
                            thinning = 30, 
                            NumIterations = 10000, 
                            burnin = 5000, 
                            DoSave=TRUE, 
                            returnNet= TRUE, 
                            doGOF=FALSE)
  
  # update the current theta
  currentTheta2 = currentTheta2 - solve(cov(t(largeContSim2$statsvec))) %*% incrementVector2
  
  # save all of those simulated statistics
  meanStats2[iterIndex, ] = rowMeans(largeContSim2$statsvec)
  
  # and for each parameter...
  for(paraIndex in 1:length(triNullThetaMeans2)){
    
    # order the simulated statistics and grab the 95% CI
    orderedStats2 = sort(largeContSim2$statsvec[paraIndex, ])
    lowerStats2[iterIndex, paraIndex] = quantile(orderedStats2, probs = 0.025)
    upperStats2[iterIndex, paraIndex] = quantile(orderedStats2, probs = 0.975)
  }
  
  # save the updated theta
  updatedTheta2[iterIndex, ] = t(currentTheta2)
}

# all of the object should be filled at the end of this main loop
# so we can shove all of it in a list
contIncrementResult2 = list(meanStats = meanStats2,
                           updatedTheta = updatedTheta2,
                           lowerStats = lowerStats2,
                           upperStats = upperStats2)

par(mfrow=c(3,2))
for (paraIndex in 1:length(triNullThetaMeans2)){
  
  # plotting the mean simulated statistics
  plot(ts(contIncrementResult2$meanStats[, paraIndex]), 
       ylim = range(contIncrementResult2$meanStats[, paraIndex],
                  contIncrementResult2$lowerStats[, paraIndex],
                  contIncrementResult2$upperStats[, paraIndex]),
     main = names(triNullThetaMeans2)[paraIndex],
     ylab = NA,
     xlab = NA)
  
  # adding the lower and upper bounds
  lines(x = c(1:nrow(contIncrementResult2$meanStats)), 
        y = contIncrementResult2$lowerStats[, paraIndex],col='red')
  lines(x = c(1:nrow(contIncrementResult2$meanStats)), 
        y = contIncrementResult2$upperStats[, paraIndex],col='red')
}

# taking the large contagion information out
largeSimStats2 = t(largeContSim2$statsvec)

# sampled edges
largeSampledEdges2 = t(largeContSim2$y)

## Briefly inspect it
summary(largeSimStats2)


```


#### Plots


```{r trigraph plot}
## set number of trials (this is the number of iterations in the simulations)
trials = 10000


# an array because we are gonna have a lot of matrices
zeroSampledArray = array(data = 0, dim = c(nrow(chosenTriGraph), ncol(chosenTriGraph), trials))
smallSampledArray = array(data = 0, dim = c(nrow(chosenTriGraph), ncol(chosenTriGraph), trials))
largeSampledArray = array(data = 0, dim = c(nrow(chosenTriGraph), ncol(chosenTriGraph), trials))

# a loop for all of the simulated sampled edges
for(trialInd in 1:trials){
  
  # turn the line graph into edge lists
  zeroSampledEdgeList = triLineEdgeList[zeroSampledEdges[trialInd,] == 1,]
  smallSampledEdgeList = triLineEdgeList[smallSampledEdges[trialInd,] == 1,]
  largeSampledEdgeList = triLineEdgeList[largeSampledEdges[trialInd,] == 1,]

    # loops one at a time
  for(edgeNo in 1:nrow(zeroSampledEdgeList)){
    
    # grab the sender
    sender = zeroSampledEdgeList[edgeNo, 1]
    
    # grab the rceiver
    receiver = zeroSampledEdgeList[edgeNo, 2]
    
    # fill in the empty matrix
    zeroSampledArray[sender, receiver, trialInd] = 1
    
    # do the same for the other end because undirected
    zeroSampledArray[receiver, sender, trialInd] = 1
  }
  
  
  # but anyways
  for(edgeNo in 1:nrow(smallSampledEdgeList)){
    
    # grab the sender
    sender = smallSampledEdgeList[edgeNo, 1]
    
    # grab the rceiver
    receiver = smallSampledEdgeList[edgeNo, 2]
    
    # fill in the empty matrix
    smallSampledArray[sender, receiver, trialInd] = 1
    
    # do the same for the other end because undirected
    smallSampledArray[receiver, sender, trialInd] = 1
  }
  
  for(edgeNo in 1:nrow(largeSampledEdgeList)){
    
    # grab the sender
    sender = largeSampledEdgeList[edgeNo, 1]
    
    # grab the rceiver
    receiver = largeSampledEdgeList[edgeNo, 2]
    
    # fill in the empty matrix
    largeSampledArray[sender, receiver, trialInd] = 1
    
    # do the same for the other end because undirected
    largeSampledArray[receiver, sender, trialInd] = 1
  }
}
gplot(zeroSampledArray[,, sample(1:10000, 1)], gmode = "graph", main = "Zero POI")
gplot(smallSampledArray[,, sample(1:10000, 1)], gmode = "graph", main = "Small POI")
gplot(largeSampledArray[,, sample(1:10000, 1)], gmode = "graph", main = "Large POI")


## appplying the calculations en masse
# turn them into networkssss
zeroSampledNets = apply(zeroSampledArray, MARGIN = 3, FUN = as.network, directed = FALSE)
smallSampledNets = apply(smallSampledArray, MARGIN = 3, FUN = as.network, directed = FALSE)
largeSampledNets = apply(largeSampledArray, MARGIN = 3, FUN = as.network, directed = FALSE)

# and calculate
zeroMetricList = lapply(zeroSampledNets, FUN = getMetrics)
smallMetricList = lapply(smallSampledNets, FUN = getMetrics)
largeMetricList = lapply(largeSampledNets, FUN = getMetrics)

# getting individual metrics
zeroDensity = sapply(zeroMetricList, function(x){x[["density"]]})
zeroClust = sapply(zeroMetricList, function(x){x[["clustCoeff"]]})
zeroCentr = sapply(zeroMetricList, function(x){x[["centralisation"]]})
zeroAvgGeo = sapply(zeroMetricList, function(x){x[["avgGeod"]]})
zeroDiam = sapply(zeroMetricList, function(x){x[["diameter"]]})
zeroAvgDeg = sapply(zeroMetricList, function(x){x[["avgDegree"]]})
zeroAvgBetw = sapply(zeroMetricList, function(x){x[["avgBetw"]]})
zeroNumIsolates = sapply(zeroMetricList, function(x){x[["numIsolates"]]})

smallDensity = sapply(smallMetricList, function(x){x[["density"]]})
smallClust = sapply(smallMetricList, function(x){x[["clustCoeff"]]})
smallCentr = sapply(smallMetricList, function(x){x[["centralisation"]]})
smallAvgGeo = sapply(smallMetricList, function(x){x[["avgGeod"]]})
smallDiam = sapply(smallMetricList, function(x){x[["diameter"]]})
smallAvgDeg = sapply(smallMetricList, function(x){x[["avgDegree"]]})
smallAvgBetw = sapply(smallMetricList, function(x){x[["avgBetw"]]})
smallNumIsolates = sapply(smallMetricList, function(x){x[["numIsolates"]]})

largeDensity = sapply(largeMetricList, function(x){x[["density"]]})
largeClust = sapply(largeMetricList, function(x){x[["clustCoeff"]]})
largeCentr = sapply(largeMetricList, function(x){x[["centralisation"]]})
largeAvgGeo = sapply(largeMetricList, function(x){x[["avgGeod"]]})
largeDiam = sapply(largeMetricList, function(x){x[["diameter"]]})
largeAvgDeg = sapply(largeMetricList, function(x){x[["avgDegree"]]})
largeAvgBetw = sapply(largeMetricList, function(x){x[["avgBetw"]]})
largeNumIsolates = sapply(largeMetricList, function(x){x[["numIsolates"]]})

# get the 'true' metric value
trueMetrics = getMetrics(as.network(chosenTriGraph, directed = FALSE))

# package
library(ggplot2)

# contagion counts
contPlotData = data.frame(contStats = c(zeroSimStats[,2], smallSimStats[,2], largeSimStats[,2]),
                          model = factor(c(rep("zeroPoi", trials), rep("smallPoi", trials), rep("largePoi", trials)),
                                           levels = c( "zeroPoi", "smallPoi", "largePoi")),
                            runs = rep(1:trials, 3))

contPlot = ggplot( data = contPlotData,
                    aes( x = contStats, col = model, fill = model)) + 
             xlab("POI Bias") + 
             ylab("Frequency") +
             geom_density(alpha = 0.4) +
             ggtitle("Diagnostics - POI Bias") + 
             theme_classic()

contPlot

# density
densityPlotData = data.frame(density = c(zeroDensity, smallDensity, largeDensity), 
                            model = factor(c(rep("zeroPoi", trials), rep("smallPoi", trials), rep("largePoi", trials)),
                                           levels = c( "zeroPoi", "smallPoi", "largePoi")),
                            runs = rep(1:trials, 3))

densityPlot = ggplot( data = densityPlotData,
                    aes( x = density, col = model, fill = model)) + 
             xlab("Density") + 
             ylab("Frequency") +
             geom_vline(xintercept = trueMetrics$density, col = "darkblue") + 
             geom_density(alpha = 0.4) +
             ggtitle("Diagnostics - Density") + 
             theme_classic()

densityPlot

# Clustering coefficient
clustPlotData = data.frame(clust = c(zeroClust, smallClust, largeClust), 
                            model = factor(c( rep("zeroPoi", trials), rep("smallPoi", trials), rep("largePoi", trials)),
                                           levels = c("zeroPoi", "smallPoi", "largePoi")),
                            runs = rep(1:trials, 3))

clustPlot = ggplot( data = clustPlotData,
                    aes( x = clust, col = model, fill = model)) + 
             xlab("Clustering coefficient") + 
             ylab("Frequency") +
             geom_vline(xintercept = trueMetrics$clustCoeff, col = "darkblue") + 
             geom_density(alpha = 0.4) +
             ggtitle("Diagnostics - Clustering coefficient") + 
             theme_classic()

clustPlot

# Centralisation
centrPlotData = data.frame(centr = c(zeroCentr, smallCentr, largeCentr), 
                            model = factor(c(rep("zeroPoi", trials), rep("smallPoi", trials), rep("largePoi", trials)),
                                           levels = c("zeroPoi", "smallPoi", "largePoi")),
                            runs = rep(1:trials, 3))

centrPlot = ggplot( data = centrPlotData,
                    aes( x = centr, col = model, fill = model)) + 
             xlab("Centralisation") + 
             ylab("Frequency") +
             geom_vline(xintercept = trueMetrics$centralisation, col = "darkblue") + 
             geom_density(alpha = 0.4) +
             ggtitle("Diagnostics - Centralisation") + 
             theme_classic()

centrPlot

# Avg geod
avgGeoPlotData = data.frame(avgGeo = c(zeroAvgGeo, smallAvgGeo, largeAvgGeo), 
                            model = factor(c(rep("zeroPoi", trials), rep("smallPoi", trials), rep("largePoi", trials)),
                                           levels = c("zeroPoi", "smallPoi", "largePoi")),
                            runs = rep(1:trials, 3))

avgGeoPlot = ggplot( data = avgGeoPlotData,
                    aes( x = avgGeo, col = model, fill = model)) + 
             xlab("Average geodesic") + 
             ylab("Frequency") +
             geom_vline(xintercept = trueMetrics$avgGeod, col = "darkblue") + 
             geom_density(alpha = 0.4) +
             ggtitle("Diagnostics - Average geodesic") + 
             theme_classic()

avgGeoPlot

# Diameter
diamPlotData = data.frame(diam = c(zeroDiam, smallDiam, largeDiam), 
                            model = factor(c(rep("zeroPoi", trials), rep("smallPoi", trials), rep("largePoi", trials)),
                                           levels = c("zeroPoi", "smallPoi", "largePoi")),
                            runs = rep(1:trials, 3))

diamPlot = ggplot( data = diamPlotData,
                    aes( x = diam, col = model, fill = model)) + 
             xlab("Diameter") + 
             ylab("Frequency") +
             geom_vline(xintercept = trueMetrics$diameter, col = "darkblue") + 
             geom_density(alpha = 0.4) +
             ggtitle("Diagnostics - Diameter") + 
             theme_classic()

diamPlot

# Avg degree
avgDegPlotData = data.frame(avgDeg = c(zeroAvgDeg, smallAvgDeg, largeAvgDeg), 
                            model = factor(c(rep("zeroPoi", trials), rep("smallPoi", trials), rep("largePoi", trials)),
                                           levels = c("zeroPoi", "smallPoi", "largePoi")),
                            runs = rep(1:trials, 3))

avgDegPlot = ggplot( data = avgDegPlotData,
                    aes( x = avgDeg, col = model, fill = model)) + 
             xlab("Average degree") + 
             ylab("Frequency") +
             geom_vline(xintercept = trueMetrics$avgDegree, col = "darkblue") + 
             geom_density(alpha = 0.4) +
             ggtitle("Diagnostics - Average degree") + 
             theme_classic()

avgDegPlot

# betw
avgBetwPlotData = data.frame(avgBetw = c(zeroAvgBetw, smallAvgBetw, largeAvgBetw), 
                            model = factor(c(rep("zeroPoi", trials), rep("smallPoi", trials), rep("largePoi", trials)),
                                           levels = c("zeroPoi", "smallPoi", "largePoi")),
                            runs = rep(1:trials, 3))

avgBetwPlot = ggplot( data = avgBetwPlotData,
                    aes( x = avgBetw, col = model, fill = model)) + 
             xlab("Average betweenness centrality") + 
             ylab("Frequency") +
             geom_vline(xintercept = trueMetrics$avgBetw, col = "darkblue") + 
             geom_density(alpha = 0.4) +
             ggtitle("Diagnostics - Average betweenness centrality") + 
             theme_classic()

avgBetwPlot

isolatesPlotData = data.frame(isolates = c(zeroNumIsolates, smallNumIsolates, largeNumIsolates), 
                            model = factor(c(rep("zeroPoi", trials), rep("smallPoi", trials), rep("largePoi", trials)),
                                           levels = c("zeroPoi", "smallPoi", "largePoi")),
                            runs = rep(1:trials, 3))

isolatesPlot =  ggplot( data = isolatesPlotData,
                    aes( x = isolates, col = model, fill = model)) + 
             xlab("Number of isolates") + 
             ylab("Frequency") +
             geom_vline(xintercept = trueMetrics$avgBetw, col = "darkblue") + 
             geom_density(alpha = 0.4) +
             ggtitle("Diagnostics - Isolate count") + 
             theme_classic()

isolatesPlot


```


### Simulated co-arrest network

#### Simulations

```{r line graph sim coAr, echo = F, eval = F}
# co arrest net

# line graph of the triangledense network
coArLineGraph = lineGraph(coEventMat)

## Slapping on a covariate
# get unique ids for dyadic cov
coArLineStr = str_split(rownames(coArLineGraph), pattern = ",")

# reformat into a more friendly data frame
coArLineEdgeList = data.frame(sender = as.numeric(unlist(lapply(coArLineStr, FUN = function(x){x[1]}))), 
                              receiver = as.numeric(unlist(lapply(coArLineStr, FUN = function(x){x[2]}))))

# get the degree
coArDegVec = rowSums(coEventMat)

# turn into a 'edge' covariate using the indices in the edge list data frame
coArDegreeCov = c()
centeredAge = (londonGangsAtt$Age - mean(londonGangsAtt$Age))/sd(londonGangsAtt$Age)

# turn into a 'edge' covariate using the indices in the edge list data frame
centAgeDiffEdgeCov = c()

# just loop it
for(edgeNo in 1:nrow(coArLineEdgeList)){

  sender = coArLineEdgeList[edgeNo, "sender"]
  receiver = coArLineEdgeList[edgeNo, "receiver"]

  centAgeDiffEdgeCov[edgeNo] = centeredAge[sender] - centeredAge[receiver]
  coArDegreeCov[edgeNo] = coArDegVec[sender] + coArDegVec[receiver]
}

# rescaling the degree covariate since its high values are giving me parameter scale grief
centCoArDegCov = scale(coArDegreeCov)

# line covs
#coArAlaamCovs = cbind(centTriDegCov)
coArAlaamCovs = cbind(centAgeDiffEdgeCov)

# make an empty outcome variable
coArLineOutcome = rep(0, times = nrow(coArLineGraph))

# specifying a sampling rate to fix, say 50% sampled (50% missing)
fixSampledRate = 0.50

# I want the density to be very precise so I'll try using less probabilistic sampling (less randomness)
# so turn that density to a number of sampled edges, rounding down
fixSampledEdges = floor(fixSampledRate *nrow(coArLineGraph))

# use the number of fixed sampled edges as the sum of some kind of index for which variable in lineOutcome is sampled
coArSampledIndex = sample(1:nrow(coArLineGraph), fixSampledEdges, replace = FALSE)

# and turn them into sampled edges
coArLineOutcome[coArSampledIndex] = 1

# check to see if it's equal
sum(coArLineOutcome) == fixSampledEdges

## Needs some kind of covariate... we can use the same as the one for the empirical covert network.
coArContAlaam <- BayesALAAM(y = coArLineOutcome,           # dependent variable
                            ADJ = coArLineGraph,           # 'network'
                            covariates = coArAlaamCovs,
                            directed = FALSE,    # directed / undirecred network
                            useDegree = FALSE,
                            burnin = 1000,
                            Iterations = 5000,   # number of iterations
                            saveFreq = 500)

# plot it to check the chains
plot(ts(coArContAlaam$Theta))

# grab the means
coArContThetaMeans <- colMeans(coArContAlaam$Theta)

# then a null contagion model
coArNullAlaam <- BayesALAAM(y = coArLineOutcome,           # dependent variable
                            ADJ = coArLineGraph,           # 'network'
                            covariates = coArAlaamCovs,   # covariates
                            directed = FALSE,    # directed / undirecred network
                            useDegree = FALSE,
                            burnin = 1000,
                            Iterations = 5000,   # number of iterations
                            saveFreq = 500,
                            contagion = 'none') 

# plot it to check the chains
plot(ts(coArNullAlaam$Theta))

# grab the means
coArNullThetaMeans <- colMeans(coArNullAlaam$Theta)

# simulating the outcome of the alaam object using the null thetas.
coArNullAlaamSim <- simulate.alaam(ALAAMobj=coArContAlaam$ALAAMobj,
                            theta=coArNullThetaMeans,
                            contagion ='simple', 
                            thinning = 30, 
                            NumIterations = 10000, 
                            burnin = 5000, 
                            DoSave=TRUE, 
                            returnNet= TRUE, 
                            doGOF=FALSE)

# inspecting the object
class(coArNullAlaamSim$statsvec)
dim(coArNullAlaamSim$statsvec)
dim(cov(t(coArNullAlaamSim$statsvec)))

## I'm breaking apart Johan's increment_theta function
# let's say we want to increase the number of contagion occurrences by 5
contIncrement = -1

# set up some number of iterations for the simulations
iterations = 20

# let's plug that into a vector for increments
incrementVector = matrix(0, nrow = length(coArNullThetaMeans), ncol =  1)

# and plug that into the contagion parameter
incrementVector[2,1] = contIncrement

# some data structures for the simulations
meanStats = matrix(0, nrow = iterations, ncol = length(coArNullThetaMeans))
lowerStats =  matrix(0, nrow = iterations, ncol = length(coArNullThetaMeans))
upperStats =  matrix(0, nrow = iterations, ncol = length(coArNullThetaMeans))
updatedTheta = matrix(0, nrow = iterations, ncol = length(coArNullThetaMeans))
currentTheta = coArNullThetaMeans

# the main simulation loop
for(iterIndex in 1:iterations){
  
  # simulate contagion
  iterAlaamSim = simulate.alaam(ALAAMobj = coArContAlaam$ALAAMobj,
                            theta=t(currentTheta),
                            contagion ='simple', 
                            thinning = 30, 
                            NumIterations = 10000, 
                            burnin = 5000, 
                            DoSave=TRUE, 
                            returnNet= TRUE, 
                            doGOF=FALSE)
  
  # update the current theta
  currentTheta = currentTheta - solve(cov(t(iterAlaamSim$statsvec))) %*% incrementVector
  
  # save all of those simulated statistics
  meanStats[iterIndex, ] = rowMeans(iterAlaamSim$statsvec)
  
  # and for each parameter...
  for(paraIndex in 1:length(coArNullThetaMeans)){
    
    # order the simulated statistics and grab the 95% CI
    orderedStats = sort(iterAlaamSim$statsvec[paraIndex, ])
    lowerStats[iterIndex, paraIndex] = quantile(orderedStats, probs = 0.025)
    upperStats[iterIndex, paraIndex] = quantile(orderedStats, probs = 0.975)
  }
  
  # save the updated theta
  updatedTheta[iterIndex, ] = t(currentTheta)
}

# all of the object should be filled at the end of this main loop
# so we can shove all of it in a list
contIncrementResult = list(meanStats = meanStats,
                           updatedTheta = updatedTheta,
                           lowerStats = lowerStats,
                           upperStats = upperStats)


# plots to check if it works
par(mfrow=c(3,2))
for (paraIndex in 1:length(coArNullThetaMeans)){
  
  # plotting the mean simulated statistics
  plot(ts(contIncrementResult$meanStats[, paraIndex]), 
       ylim = range(contIncrementResult$meanStats[, paraIndex],
                  contIncrementResult$lowerStats[, paraIndex],
                  contIncrementResult$upperStats[, paraIndex]),
     main = names(coArNullThetaMeans)[paraIndex],
     ylab = NA,
     xlab = NA)
  
  # adding the lower and upper bounds
  lines(x = c(1:nrow(contIncrementResult$meanStats)), 
        y = contIncrementResult$lowerStats[, paraIndex],col='red')
  lines(x = c(1:nrow(contIncrementResult$meanStats)), 
        y = contIncrementResult$upperStats[, paraIndex],col='red')
}

#  no contagion, taking nullAlaamSim
zeroSimStats = t(coArNullAlaamSim$statsvec)

# sampled edges
zeroSampledEdges = t(coArNullAlaamSim$y)

## Briefly inspect it
summary(zeroSimStats)

# Now let's increment it by an arbitrarily 'small' amount to emulate a 'small' amount of contagion
# let's say we want to increase the number of contagion occurrences by 5
contIncrement = -25

# set up some number of iterations for the simulations, 2 for this case, one to initialise and another one for the single contagion increment
iterations = 2

# let's plug that into a vector for increments
incrementVector = matrix(0, nrow = length(coArNullThetaMeans), ncol =  1)

# and plug that into the contagion parameter
incrementVector[2,1] = contIncrement

# some data structures for the simulations
meanStats = matrix(0, nrow = iterations, ncol = length(coArNullThetaMeans))
lowerStats =  matrix(0, nrow = iterations, ncol = length(coArNullThetaMeans))
upperStats =  matrix(0, nrow = iterations, ncol = length(coArNullThetaMeans))
updatedTheta = matrix(0, nrow = iterations, ncol = length(coArNullThetaMeans))
currentTheta = coArNullThetaMeans

# the main simulation loop
for(iterIndex in 1:iterations){
  
  # simulate contagion
  smallContSim = simulate.alaam(ALAAMobj = coArContAlaam$ALAAMobj,
                            theta=t(currentTheta),
                            contagion ='simple', 
                            thinning = 30, 
                            NumIterations = 10000, 
                            burnin = 5000, 
                            DoSave=TRUE, 
                            returnNet= TRUE, 
                            doGOF=FALSE)
  
  # update the current theta
  currentTheta = currentTheta - solve(cov(t(smallContSim$statsvec))) %*% incrementVector
  
  # save all of those simulated statistics
  meanStats[iterIndex, ] = rowMeans(smallContSim$statsvec)
  
  # and for each parameter...
  for(paraIndex in 1:length(coArNullThetaMeans)){
    
    # order the simulated statistics and grab the 95% CI
    orderedStats = sort(smallContSim$statsvec[paraIndex, ])
    lowerStats[iterIndex, paraIndex] = quantile(orderedStats, probs = 0.025)
    upperStats[iterIndex, paraIndex] = quantile(orderedStats, probs = 0.975)
  }
  
  # save the updated theta
  updatedTheta[iterIndex, ] = t(currentTheta)
}

# all of the object should be filled at the end of this main loop
# so we can shove all of it in a list
contIncrementResult = list(meanStats = meanStats,
                           updatedTheta = updatedTheta,
                           lowerStats = lowerStats,
                           upperStats = upperStats)

par(mfrow=c(3,2))
for (paraIndex in 1:length(coArNullThetaMeans)){
  
  # plotting the mean simulated statistics
  plot(ts(contIncrementResult$meanStats[, paraIndex]), 
       ylim = range(contIncrementResult$meanStats[, paraIndex],
                  contIncrementResult$lowerStats[, paraIndex],
                  contIncrementResult$upperStats[, paraIndex]),
     main = names(coArNullThetaMeans)[paraIndex],
     ylab = NA,
     xlab = NA)
  
  # adding the lower and upper bounds
  lines(x = c(1:nrow(contIncrementResult$meanStats)), 
        y = contIncrementResult$lowerStats[, paraIndex],col='red')
  lines(x = c(1:nrow(contIncrementResult$meanStats)), 
        y = contIncrementResult$upperStats[, paraIndex],col='red')
}

# taking the small contagion information out
#  no contagion, taking nullAlaamSim
smallSimStats = t(smallContSim$statsvec)

# sampled edges
smallSampledEdges = t(smallContSim$y)

## Briefly inspect it
summary(smallSimStats)

## Same thing, but large
# Now let's increment it by an arbitrarily 'small' amount to emulate a 'small' amount of contagion
# let's say we want to increase the number of contagion occurrences by 5
contIncrement = -60

# set up some number of iterations for the simulations, 2 for this case, one to initialise and another one for the single contagion increment
iterations = 2

# let's plug that into a vector for increments
incrementVector = matrix(0, nrow = length(coArNullThetaMeans), ncol =  1)

# and plug that into the contagion parameter
incrementVector[2,1] = contIncrement

# some data structures for the simulations
meanStats = matrix(0, nrow = iterations, ncol = length(coArNullThetaMeans))
lowerStats =  matrix(0, nrow = iterations, ncol = length(coArNullThetaMeans))
upperStats =  matrix(0, nrow = iterations, ncol = length(coArNullThetaMeans))
updatedTheta = matrix(0, nrow = iterations, ncol = length(coArNullThetaMeans))
currentTheta = currentTheta

# the main simulation loop
for(iterIndex in 1:iterations){
  
  # simulate contagion
  largeContSim = simulate.alaam(ALAAMobj = coArContAlaam$ALAAMobj,
                            theta=t(currentTheta),
                            contagion ='simple', 
                            thinning = 30, 
                            NumIterations = 10000, 
                            burnin = 5000, 
                            DoSave=TRUE, 
                            returnNet= TRUE, 
                            doGOF=FALSE)
  
  # update the current theta
  currentTheta = currentTheta - solve(cov(t(largeContSim$statsvec))) %*% incrementVector
  
  # save all of those simulated statistics
  meanStats[iterIndex, ] = rowMeans(largeContSim$statsvec)
  
  # and for each parameter...
  for(paraIndex in 1:length(coArNullThetaMeans)){
    
    # order the simulated statistics and grab the 95% CI
    orderedStats = sort(largeContSim$statsvec[paraIndex, ])
    lowerStats[iterIndex, paraIndex] = quantile(orderedStats, probs = 0.025)
    upperStats[iterIndex, paraIndex] = quantile(orderedStats, probs = 0.975)
  }
  
  # save the updated theta
  updatedTheta[iterIndex, ] = t(currentTheta)
}

# all of the object should be filled at the end of this main loop
# so we can shove all of it in a list
contIncrementResult = list(meanStats = meanStats,
                           updatedTheta = updatedTheta,
                           lowerStats = lowerStats,
                           upperStats = upperStats)

par(mfrow=c(3,2))
for (paraIndex in 1:length(coArNullThetaMeans)){
  
  # plotting the mean simulated statistics
  plot(ts(contIncrementResult$meanStats[, paraIndex]), 
       ylim = range(contIncrementResult$meanStats[, paraIndex],
                  contIncrementResult$lowerStats[, paraIndex],
                  contIncrementResult$upperStats[, paraIndex]),
     main = names(coArNullThetaMeans)[paraIndex],
     ylab = NA,
     xlab = NA)
  
  # adding the lower and upper bounds
  lines(x = c(1:nrow(contIncrementResult$meanStats)), 
        y = contIncrementResult$lowerStats[, paraIndex],col='red')
  lines(x = c(1:nrow(contIncrementResult$meanStats)), 
        y = contIncrementResult$upperStats[, paraIndex],col='red')
}

# taking the large contagion information out
largeSimStats = t(largeContSim$statsvec)

# sampled edges
largeSampledEdges = t(largeContSim$y)

## Briefly inspect it
summary(largeSimStats)


```


#### Plots




```{r coarsim plot, echo = F, eval = F}
## set number of trials (this is the number of iterations in the simulations)
trials = 10000


# an array because we are gonna have a lot of matrices
zeroSampledArray = array(data = 0, dim = c(nrow(coEventMat), ncol(coEventMat), trials))
smallSampledArray = array(data = 0, dim = c(nrow(coEventMat), ncol(coEventMat), trials))
largeSampledArray = array(data = 0, dim = c(nrow(coEventMat), ncol(coEventMat), trials))

# a loop for all of the simulated sampled edges
for(trialInd in 1:trials){
  
  # turn the line graph into edge lists
  zeroSampledEdgeList = coArLineEdgeList[zeroSampledEdges[trialInd,] == 1,]
  smallSampledEdgeList = coArLineEdgeList[smallSampledEdges[trialInd,] == 1,]
  largeSampledEdgeList = coArLineEdgeList[largeSampledEdges[trialInd,] == 1,]

    # loops one at a time
  for(edgeNo in 1:nrow(zeroSampledEdgeList)){
    
    # grab the sender
    sender = zeroSampledEdgeList[edgeNo, 1]
    
    # grab the rceiver
    receiver = zeroSampledEdgeList[edgeNo, 2]
    
    # fill in the empty matrix
    zeroSampledArray[sender, receiver, trialInd] = 1
    
    # do the same for the other end because undirected
    zeroSampledArray[receiver, sender, trialInd] = 1
  }
  
  
  # but anyways
  for(edgeNo in 1:nrow(smallSampledEdgeList)){
    
    # grab the sender
    sender = smallSampledEdgeList[edgeNo, 1]
    
    # grab the rceiver
    receiver = smallSampledEdgeList[edgeNo, 2]
    
    # fill in the empty matrix
    smallSampledArray[sender, receiver, trialInd] = 1
    
    # do the same for the other end because undirected
    smallSampledArray[receiver, sender, trialInd] = 1
  }
  
  for(edgeNo in 1:nrow(largeSampledEdgeList)){
    
    # grab the sender
    sender = largeSampledEdgeList[edgeNo, 1]
    
    # grab the rceiver
    receiver = largeSampledEdgeList[edgeNo, 2]
    
    # fill in the empty matrix
    largeSampledArray[sender, receiver, trialInd] = 1
    
    # do the same for the other end because undirected
    largeSampledArray[receiver, sender, trialInd] = 1
  }
}
gplot(zeroSampledArray[,, sample(1:10000, 1)], gmode = "graph", main = "Zero contagion")
gplot(smallSampledArray[,, sample(1:10000, 1)], gmode = "graph", main = "Small contagion")
gplot(largeSampledArray[,, sample(1:10000, 1)], gmode = "graph", main = "Large contagion")


## appplying the calculations en masse
# turn them into networkssss
zeroSampledNets = apply(zeroSampledArray, MARGIN = 3, FUN = as.network, directed = FALSE)
smallSampledNets = apply(smallSampledArray, MARGIN = 3, FUN = as.network, directed = FALSE)
largeSampledNets = apply(largeSampledArray, MARGIN = 3, FUN = as.network, directed = FALSE)

# and calculate
zeroMetricList = lapply(zeroSampledNets, FUN = getMetrics)
smallMetricList = lapply(smallSampledNets, FUN = getMetrics)
largeMetricList = lapply(largeSampledNets, FUN = getMetrics)

# getting individual metrics
zeroDensity = sapply(zeroMetricList, function(x){x[["density"]]})
zeroClust = sapply(zeroMetricList, function(x){x[["clustCoeff"]]})
zeroCentr = sapply(zeroMetricList, function(x){x[["centralisation"]]})
zeroAvgGeo = sapply(zeroMetricList, function(x){x[["avgGeod"]]})
zeroDiam = sapply(zeroMetricList, function(x){x[["diameter"]]})
zeroAvgDeg = sapply(zeroMetricList, function(x){x[["avgDegree"]]})
zeroAvgBetw = sapply(zeroMetricList, function(x){x[["avgBetw"]]})

smallDensity = sapply(smallMetricList, function(x){x[["density"]]})
smallClust = sapply(smallMetricList, function(x){x[["clustCoeff"]]})
smallCentr = sapply(smallMetricList, function(x){x[["centralisation"]]})
smallAvgGeo = sapply(smallMetricList, function(x){x[["avgGeod"]]})
smallDiam = sapply(smallMetricList, function(x){x[["diameter"]]})
smallAvgDeg = sapply(smallMetricList, function(x){x[["avgDegree"]]})
smallAvgBetw = sapply(smallMetricList, function(x){x[["avgBetw"]]})

largeDensity = sapply(largeMetricList, function(x){x[["density"]]})
largeClust = sapply(largeMetricList, function(x){x[["clustCoeff"]]})
largeCentr = sapply(largeMetricList, function(x){x[["centralisation"]]})
largeAvgGeo = sapply(largeMetricList, function(x){x[["avgGeod"]]})
largeDiam = sapply(largeMetricList, function(x){x[["diameter"]]})
largeAvgDeg = sapply(largeMetricList, function(x){x[["avgDegree"]]})
largeAvgBetw = sapply(largeMetricList, function(x){x[["avgBetw"]]})


# get the 'true' metric value
trueMetrics = getMetrics(as.network(coEventMat, directed = FALSE))

# package
library(ggplot2)

# contagion counts
contPlotData = data.frame(contStats = c(zeroSimStats[,2], smallSimStats[,2], largeSimStats[,2]),
                          model = factor(c(rep("ZeroCont", trials), rep("SmallCont", trials), rep("LargeCont", trials)),
                                           levels = c( "ZeroCont", "SmallCont", "LargeCont")),
                            runs = rep(1:trials, 3))

contPlot = ggplot( data = contPlotData,
                    aes( x = contStats, col = model, fill = model)) + 
             xlab("Contagion") + 
             ylab("Frequency") +
             geom_density(alpha = 0.4) +
             ggtitle("Diagnostics - Contagion") + 
             theme_classic()

contPlot

# density
densityPlotData = data.frame(density = c(zeroDensity, smallDensity, largeDensity), 
                            model = factor(c(rep("ZeroCont", trials), rep("SmallCont", trials), rep("LargeCont", trials)),
                                           levels = c( "ZeroCont", "SmallCont", "LargeCont")),
                            runs = rep(1:trials, 3))

densityPlot = ggplot( data = densityPlotData,
                    aes( x = density, col = model, fill = model)) + 
             xlab("Density") + 
             ylab("Frequency") +
             geom_vline(xintercept = trueMetrics$density, col = "darkblue") + 
             geom_density(alpha = 0.4) +
             ggtitle("Diagnostics - Density") + 
             theme_classic()

densityPlot

# Clustering coefficient
clustPlotData = data.frame(clust = c(zeroClust, smallClust, largeClust), 
                            model = factor(c( rep("ZeroCont", trials), rep("SmallCont", trials), rep("LargeCont", trials)),
                                           levels = c("ZeroCont", "SmallCont", "LargeCont")),
                            runs = rep(1:trials, 3))

clustPlot = ggplot( data = clustPlotData,
                    aes( x = clust, col = model, fill = model)) + 
             xlab("Clustering coefficient") + 
             ylab("Frequency") +
             geom_vline(xintercept = trueMetrics$clustCoeff, col = "darkblue") + 
             geom_density(alpha = 0.4) +
             ggtitle("Diagnostics - Clustering coefficient") + 
             theme_classic()

clustPlot

# Centralisation
centrPlotData = data.frame(centr = c(zeroCentr, smallCentr, largeCentr), 
                            model = factor(c(rep("ZeroCont", trials), rep("SmallCont", trials), rep("LargeCont", trials)),
                                           levels = c("ZeroCont", "SmallCont", "LargeCont")),
                            runs = rep(1:trials, 3))

centrPlot = ggplot( data = centrPlotData,
                    aes( x = centr, col = model, fill = model)) + 
             xlab("Centralisation") + 
             ylab("Frequency") +
             geom_vline(xintercept = trueMetrics$centralisation, col = "darkblue") + 
             geom_density(alpha = 0.4) +
             ggtitle("Diagnostics - Centralisation") + 
             theme_classic()

centrPlot

# Avg geod
avgGeoPlotData = data.frame(avgGeo = c(zeroAvgGeo, smallAvgGeo, largeAvgGeo), 
                            model = factor(c(rep("ZeroCont", trials), rep("SmallCont", trials), rep("LargeCont", trials)),
                                           levels = c("ZeroCont", "SmallCont", "LargeCont")),
                            runs = rep(1:trials, 3))

avgGeoPlot = ggplot( data = avgGeoPlotData,
                    aes( x = avgGeo, col = model, fill = model)) + 
             xlab("Average geodesic") + 
             ylab("Frequency") +
             geom_vline(xintercept = trueMetrics$avgGeod, col = "darkblue") + 
             geom_density(alpha = 0.4) +
             ggtitle("Diagnostics - Average geodesic") + 
             theme_classic()

avgGeoPlot

# Diameter
diamPlotData = data.frame(diam = c(zeroDiam, smallDiam, largeDiam), 
                            model = factor(c(rep("ZeroCont", trials), rep("SmallCont", trials), rep("LargeCont", trials)),
                                           levels = c("ZeroCont", "SmallCont", "LargeCont")),
                            runs = rep(1:trials, 3))

diamPlot = ggplot( data = diamPlotData,
                    aes( x = diam, col = model, fill = model)) + 
             xlab("Diameter") + 
             ylab("Frequency") +
             geom_vline(xintercept = trueMetrics$diameter, col = "darkblue") + 
             geom_density(alpha = 0.4) +
             ggtitle("Diagnostics - Diameter") + 
             theme_classic()

diamPlot

# Avg degree
avgDegPlotData = data.frame(avgDeg = c(zeroAvgDeg, smallAvgDeg, largeAvgDeg), 
                            model = factor(c(rep("ZeroCont", trials), rep("SmallCont", trials), rep("LargeCont", trials)),
                                           levels = c("ZeroCont", "SmallCont", "LargeCont")),
                            runs = rep(1:trials, 3))

avgDegPlot = ggplot( data = avgDegPlotData,
                    aes( x = avgDeg, col = model, fill = model)) + 
             xlab("Average degree") + 
             ylab("Frequency") +
             geom_vline(xintercept = trueMetrics$avgDegree, col = "darkblue") + 
             geom_density(alpha = 0.4) +
             ggtitle("Diagnostics - Average degree") + 
             theme_classic()

avgDegPlot

# betw
avgBetwPlotData = data.frame(avgBetw = c(zeroAvgBetw, smallAvgBetw, largeAvgBetw), 
                            model = factor(c(rep("ZeroCont", trials), rep("SmallCont", trials), rep("LargeCont", trials)),
                                           levels = c("ZeroCont", "SmallCont", "LargeCont")),
                            runs = rep(1:trials, 3))

avgBetwPlot = ggplot( data = avgBetwPlotData,
                    aes( x = avgBetw, col = model, fill = model)) + 
             xlab("Average betweenness centrality") + 
             ylab("Frequency") +
             geom_vline(xintercept = trueMetrics$avgBetw, col = "darkblue") + 
             geom_density(alpha = 0.4) +
             ggtitle("Diagnostics - Average betweenness centrality") + 
             theme_classic()

avgBetwPlot

```
